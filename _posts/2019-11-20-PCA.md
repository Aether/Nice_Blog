---
layout: post
title: "ğŸ³ä¸»æˆåˆ†åˆ†æ PCA"
subtitle: ""
date: 2019-11-24
author: Aether
category: coding
tags: CODE MACHINELEARNING
finished: true
---

# ğŸ³ é™ç»´

## ä¸»æˆåˆ†åˆ†æ *Principal Component Analysis* â€”â€” PCA

PCAçš„æœ¬è´¨æ˜¯å°†$n$ç»´æ•°æ®æŠ•å½±åˆ°$k$ç»´ç©ºé—´ä¸­ã€‚è‹¥å­˜åœ¨ä¸€ä¸ªè¶…å¹³é¢ï¼Œå¯ä»¥å¯¹æ­£äº¤å±æ€§ç©ºé—´ä¸­çš„æ ·æœ¬ç‚¹è¿›è¡Œæ°å½“çš„è¡¨è¾¾ï¼Œé‚£ä¹ˆè¿™ä¸ªè¶…å¹³é¢å…·æœ‰æœ€è¿‘é‡æ„æ€§å’Œæœ€å¤§å¯åˆ†æ€§ã€‚

- **æœ€è¿‘é‡æ„æ€§**ï¼šæ ·æœ¬ç‚¹åˆ°è¿™ä¸ªè¶…å¹³é¢çš„è·ç¦»éƒ½è¶³å¤Ÿè¿‘
- **æœ€å¤§å¯åˆ†æ€§**ï¼šæ ·æœ¬ç‚¹åœ¨è¿™ä¸ªè¶…å¹³é¢ä¸Šçš„æŠ•å½±å°½å¯èƒ½åˆ†å¼€

## ä»æœ€å¤§å¯åˆ†æ€§è¯æ˜

â€‹	æ ·æœ¬ç‚¹$\boldsymbol x_i $åœ¨æ–°ç©ºé—´ä¸­è¶…å¹³é¢ä¸Šçš„æŠ•å½±æ˜¯$\bf W^T \boldsymbol x_i $ï¼Œè‹¥ä½¿æ‰€æœ‰æ ·æœ¬ç‚¹çš„æŠ•å½±å°½å¯èƒ½åˆ†å¼€ï¼Œåˆ™åº”è¯¥ä½¿æŠ•å½±åæ ·æœ¬ç‚¹çš„æ–¹å·®æœ€å¤§åŒ–ã€‚æŠ•å½±åæ ·æœ¬ç‚¹çš„æ–¹å·®ä¸º$\sum_i \bf W^T \boldsymbol x_i \boldsymbol x_i^T\bf W$ï¼Œåˆ™ä¼˜åŒ–ç›®æ ‡å’Œé™åˆ¶æ¡ä»¶å¦‚ä¸‹ï¼š


$$
\max_{\boldsymbol W} \ \rm{tr}( \bf W^T\bf X \bf X^T\bf W )
$$

$$
\rm {s.t.}  \bf W^T \bf W = \bf I
$$

ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•ï¼š


$$
\bf X \bf X^T\bf W = \lambda \bf W
$$
å¯¹åæ–¹å·®çŸ©é˜µ$\boldsymbol X \boldsymbol X^T$è¿›è¡Œç‰¹å¾å€¼åˆ†è§£ï¼Œå¹¶å°†æ±‚çš„çš„ç‰¹å¾å€¼è¿›è¡Œæ’åºï¼Œå–å‰$k$ä¸ªæœ€å¤§çš„ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡æ„æˆæŠ•å½±çŸ©é˜µ$\bf W = \{\boldsymbol w_1,\boldsymbol w_2, \dots,\boldsymbol w_k\}$

æ³¨ï¼š


$$
{\bf X} =\left[    \begin{matrix}        {\boldsymbol x}^{(1)} - \overline {\bf X}\\        {\boldsymbol x}^{(2)}- \overline {\bf X} \\        \vdots \\        {\boldsymbol x}^{(m)} - \overline {\bf X}   \end{matrix}    \right] =    \left[        \begin{matrix}            x^{(1)}_{1}- \overline {x}_1 & x^{(1)}_{2}- \overline {x}_2   & \cdots & x^{(1)}_{n}- \overline {x}_n   \\            x^{(2)}_{1}- \overline {x}_1 & x^{(2)}_{2} - \overline {x}_2  & \cdots & x^{(2)}_{n}- \overline {x}_n   \\            \vdots & \vdots & \ddots & \vdots \\            x^{(m)}_{1}- \overline {x}_1 & x^{(m)}_{2}- \overline {x}_2 & \cdots & x^{(m)}_{n}- \overline {x}_n        \end{matrix}        \right]
$$


æ•…$\boldsymbol X \boldsymbol X^T$ä¸ºåæ–¹å·®çŸ©é˜µ

## ç®—æ³•æµç¨‹

ç»™å®šæ•°æ®é›†$D = \{ \boldsymbol x_1, \boldsymbol x_2, \dots, \boldsymbol x_m\}$ï¼Œå¯¹æ ·æœ¬è¿›è¡Œä¸­å¿ƒåŒ–ï¼Œå³


$$
\boldsymbol x_i \leftarrow \boldsymbol x_i - \boldsymbol \mu
$$


å…¶ä¸­${\boldsymbol \mu} = \frac{1}{m}\sum\limits_{j = 1}^m{\boldsymbol x}_j$ï¼Œä¸ºæ•°æ®é›†çš„$D$çš„å‡å€¼å‘é‡ã€‚è¿™ä¸ªæ­¥éª¤ç›¸å½“äºå¹³ç§»åæ ‡è½´åˆ°æ‰€æœ‰æ•°æ®ç‚¹çš„å¹³å‡ä¸­ç‚¹ä½ç½®ã€‚

<img src="../img/PCA.png" alt="6" style="zoom:50%;" />

â€‹	å½“æ•°æ®å—åˆ°å™ªå£°å½±å“æ—¶ï¼Œæœ€å°çš„ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡å¾€å¾€ä¸å™ªå£°æœ‰å…³ï¼Œå°†å®ƒä»¬èˆå¼ƒåœ¨ä¸€å®šç¨‹åº¦ä¸Šèµ·åˆ°å»å™ªçš„æ•ˆæœã€‚

## ä¿¡å™ªæ¯” SNR â€”â€” *Signal to Noise Ratio*

ä¿¡å™ªæ¯”å…¬å¼å¦‚ä¸‹ï¼š


$$
{SNR} = 10Â·\log_{10}\left[\frac{\sum\limits_{x=1}^{N_x}\sum\limits_{y=1}^{N_y}\left[f(x,y)\right]^2}{\sum\limits_{x=1}^{N_x}\sum\limits_{y=1}^{N_y}\left[f(x,y)-\hat f(x,y)\right]^2}\right]
$$





è®¾æ ·æœ¬ä¸ªæ•°ä¸º$m$ï¼Œç»´æ•°ä¸º$n$
$$
\hat y = X^T\boldsymbol \theta_0 + \sum_{j=1}^Mc_jÂ·\max
\{0,X^T\boldsymbol \theta_j\}
$$

$$
\boldsymbol \theta = \left[\begin{matrix}     b  \\     \theta_1 \\    \theta_2\\  \vdots\\     \theta_n\end{matrix}\right],
\boldsymbol x = \left[\begin{matrix}   1\\   x_1  \\     x_2 \\       \vdots\\     x_n\end{matrix}\right] \rightarrow f(x)= \boldsymbol \theta^T \boldsymbol x
$$


$$
{\boldsymbol \theta} =\left[    
\begin{matrix}        
{\boldsymbol \theta}^{(1)}\\        
{\boldsymbol \theta}^{(2)} \\        
\vdots \\        
{\boldsymbol \theta}^{(M)} 
\end{matrix}    \right] =    
\left[        
\begin{matrix}            
\theta^{(1)}_{1} & \theta^{(1)}_{2}  &\dots& \theta^{(1)}_{n}   \\      

\theta^{(2)}_{1} & \theta^{(2)}_{2}  &\dots& \theta^{(2)}_{n}   \\   
\vdots&\vdots&\ddots&\vdots&\\

\theta^{(M)}_{1} & \theta^{(M)}_{2}  &\dots& \theta^{(M)}_{n}   \\   

\end{matrix}        
\right] 

\boldsymbol X = 
\left[
\begin{matrix}   
1&1&\dots&1\\  
x^{(1)}_1&x^{(2)}_1&\dots&x^{(m)}_1  \\     
x^{(1)}_2&x^{(2)}_2&\dots&x^{(m)}_2 \\       
\vdots\\     
x^{(1)}_n&x^{(2)}_n&\dots&x^{(m)}_n
\end{matrix}

\right]

\\

\boldsymbol \theta \boldsymbol X = 
\left[\begin{matrix}   
 
\boldsymbol \theta^{(1)}\boldsymbol x^{(1)} &
\boldsymbol \theta^{(1)}\boldsymbol x^{(2)} &
\dots &
\boldsymbol \theta^{(1)}\boldsymbol x^{(m)}\\ 

\boldsymbol \theta^{(2)}\boldsymbol x^{(1)} &
\boldsymbol \theta^{(2)}\boldsymbol x^{(2)} &
\dots &
\boldsymbol \theta^{(2)}\boldsymbol x^{(m)}\\    

\vdots&\vdots&\ddots&\vdots\\     
 
\boldsymbol \theta^{(M)}\boldsymbol x^{(1)} &
\boldsymbol \theta^{(M)}\boldsymbol x^{(2)} &
\dots &
\boldsymbol \theta^{(M)}\boldsymbol x^{(m)}\\   
\end{matrix}

\right]
\\
\boldsymbol \theta^{(j)} \boldsymbol x^{(k)} =  \sum  \boldsymbol \theta^{(j)}_i \boldsymbol x^{(k)}_i
$$


