I"÷<h2 id="å¯¹æ•°å‡ ç‡å›å½’-logitstic-regression">å¯¹æ•°å‡ ç‡å›å½’ Logitstic Regression</h2>

<p>è€ƒè™‘äºŒåˆ†ç±»ä»»åŠ¡ï¼Œå°†çº¿æ€§å›å½’æ¨¡å‹çš„é¢„æµ‹å€¼$h(\boldsymbol x) =\boldsymbol{w}^T\boldsymbol{x} + b$è½¬æ¢ä¸º0/1å€¼</p>

<h4 id="å¯¹æ•°å‡ ç‡å‡½æ•°-sigmoid">å¯¹æ•°å‡ ç‡å‡½æ•° Sigmoid</h4>

<script type="math/tex; mode=display">y = \frac{1}{1+e^{-z}}</script>

<p><img src="/Users/aether/Desktop/å­¦ä¹ èµ„æ–™/æœºå™¨å­¦ä¹ /ç¬”è®°/Sigmoid.png" style="zoom:38%;" /></p>

<p>å½“$z&gt;0$æ—¶ï¼Œ$Sigmoid&gt;0$ï¼Œä¸”$z$è¶Šå¤§ï¼Œ$Sigmoid$è¶Šæ¥è¿‘$1$ï¼›$z&lt;0$æ—¶ï¼Œ$Sigmoid&lt;0$ï¼Œ$z$è¶Šå°ï¼Œ$Sigmoid$è¶Šæ¥è¿‘$0$ã€‚</p>

<p>å°†$h(\boldsymbol x)$ä»£å…¥ï¼Œå¯å°†é¢„æµ‹å€¼è½¬æ¢ä¸º0/1å€¼ï¼Œå¾—
<script type="math/tex">\hat y = \frac{1}{1+e^{-(\boldsymbol{w}^T\boldsymbol{x}+b)}}</script>
çº¿æ€§æ¨¡å‹å¯è¡¨ç¤ºä¸º
<script type="math/tex">h =\boldsymbol{w}^T\boldsymbol{x} + b = \ln \frac{y}{1-y}</script>
è®¾$y$ä¸ºæ ·æœ¬$\boldsymbol{x}$ä¸ºæ­£ä¾‹çš„å¯èƒ½æ€§ï¼Œå³åéªŒæ¦‚ç‡ä¼°è®¡$p(y=1|\boldsymbol{x})$ï¼Œ$1-y$ä¸ºåä¾‹çš„å¯èƒ½æ€§
<script type="math/tex">\hat y = \frac{1}{1+e^{-(\boldsymbol{w}^T\boldsymbol{x}+b)}}</script></p>

<script type="math/tex; mode=display">\ln \frac{y}{1-y}=\boldsymbol{w}^T\boldsymbol{x}+b = \ln \frac{p(y=1|\boldsymbol{x})}{p(y=0|\boldsymbol{x})}</script>

<p>å…¶ä¸­$\frac{y}{1-y}$ä¸º<strong>å‡ ç‡</strong>oddsï¼Œ$\ln \frac{y}{1-y}$ä¸º<strong>å¯¹æ•°å‡ ç‡</strong>logit</p>

<p>æ¦‚ç‡åˆ†å¸ƒå¦‚ä¸‹
<script type="math/tex">p(y=1|\boldsymbol{x}) = \frac{e^{\boldsymbol{w}^T\boldsymbol{x}+b}}{1+e^{\boldsymbol{w}^T\boldsymbol{x}+b}}\\
p(y=0|\boldsymbol{x}) = \frac{1}{1+e^{\boldsymbol{w}^T\boldsymbol{x}+b}}</script>
å¯é€šè¿‡<strong>æå¤§ä¼¼ç„¶æ³•</strong>ä¼°è®¡$\boldsymbol{w}$å’Œ$b$ï¼Œè®¾æ•°æ®é›†ä¸º${(\boldsymbol{x_i},y_i)}_{i-1}^m$
<script type="math/tex">\ln L(\boldsymbol{w},b)=\sum _{i=1}^m \ln p(y_i|\boldsymbol{x}_i;\boldsymbol{w},b)</script></p>

<h4 id="ä»£ä»·å‡½æ•°-cost-function">ä»£ä»·å‡½æ•° Cost Function</h4>

<p>ç”±äºçš„$Sigmoid$å‡½æ•°ä½¿ä¹‹å‰ä½¿ç”¨çš„ä»£ä»·å‡½æ•°æˆä¸ºéå‡¸å‡½æ•°ï¼Œå®šä¹‰æ–°ä»£ä»·å‡½æ•°ä¸º</p>

<script type="math/tex; mode=display">Cost(\hat y (x),y) = 
\left\{
 \begin{array}{**}
-\log(\hat y) , y = 1 \\
-\log(1-\hat y) , y = 0
\end{array}
\right. 
 = -y\log(\hat y)-(1-y)\log(1-\hat y)</script>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}{}
Loss& =\frac{1}{m}\sum_{i=1}^mCost(\hat y ^{(i)},y^{(i)}) \\
& = -\frac{1}{m}\sum_{i=1}^m [y^{(i)}\log\hat y ^{(i)}+(1-y^{(i)})\log(1-\hat y ^{(i)}) ]
\end{align} %]]></script>

<p>$Loss$çš„å¯¼æ•°åŒ–ç®€ç»“æœå¦‚ä¸‹ï¼š
<script type="math/tex">Loss(\boldsymbol \theta)= -\frac{1}{m}\sum_{i=1}^m [y^{(i)}\log\frac{1}{1+e^{-\boldsymbol{\theta}^T\boldsymbol{x}}}+(1-y^{(i)})\log(1-\frac{1}{1+e^{-\boldsymbol{\theta}^T\boldsymbol{x}}} ]</script></p>

<script type="math/tex; mode=display">\frac{\partial Loss}{\partial \boldsymbol \theta_j} = 
\frac{1}{m}\sum_{i=1}^m(\hat y^{(i)}-y^{(i)})x_j^{(i)}</script>

<h4 id="æ¢¯åº¦ä¸‹é™-gradient-descent">æ¢¯åº¦ä¸‹é™ Gradient Descent</h4>

<p>å¦‚æœ$Loss(\boldsymbol w )$å¦‚æœåœ¨$\boldsymbol w_i$ç‚¹å¯å¾®ä¸”æœ‰å®šä¹‰ï¼Œæ¢¯åº¦ $\nabla Loss(\boldsymbol w _i)$ä¸ºå‡½æ•°å¢é•¿æœ€å¿«çš„æ–¹å‘ï¼Œå› æ­¤æ¢¯åº¦çš„åæ–¹å‘$-\nabla Loss(\boldsymbol w _i)$ä¸ºå‡½æ•°ä¸‹é™æœ€å¿«çš„æ–¹å‘ã€‚è®¾$\alpha$ä¸ºå­¦ä¹ ç‡ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹å…¬å¼è¿›è¡Œè¿­ä»£ï¼š
<script type="math/tex">% <![CDATA[
\begin{align}{}
\boldsymbol w _{i+1}& = \boldsymbol w _i âˆ’ Î± \nabla Loss(\boldsymbol w _i)\\
& = \boldsymbol w _i âˆ’ Î± \frac{\partial}{\partial\boldsymbol w _i}Loss(\boldsymbol w) \\
& = \boldsymbol w _i âˆ’ Î± \frac{1}{m} \sum_{j=1}^m (\hat y^{(j)}-y^{(j)})x_i^{(j)} 
\end{align} %]]></script></p>

<h4 id="æ­£åˆ™åŒ–">æ­£åˆ™åŒ–</h4>

<p>å‘ä»£ä»·å‡½æ•°ä¸­åŠ å…¥L2æ­£åˆ™é¡¹
<script type="math/tex">Loss =\frac{1}{m}\sum_{i=1}^m [Cost(\hat y (x)^{(i)},y^{(i)})+\lambda \sum \limits_{j=1}^n \boldsymbol w^2_j]</script>
æ¢¯åº¦ä¸‹é™æ³•è¿­ä»£å…¬å¼ä¸º
<script type="math/tex">\boldsymbol w _{i+1}= \boldsymbol w _i âˆ’ Î± \frac{1}{m} \sum_{j=1}^m (\hat y(x^{(j)})-y^{(j)})x_i^{(j)} + \frac{\lambda}{m}\boldsymbol w _i</script></p>

<h4 id="ä¼˜åŒ–ç›®æ ‡">ä¼˜åŒ–ç›®æ ‡</h4>

<script type="math/tex; mode=display">\min_\theta \frac{1}{m} \left[ \sum_{i=1}^m y^{(i)}\log(h_{\theta}(x^{(i)}))+(1-y^{(i)})\log(1-h_{\theta}(x^{(i)}))\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2</script>

:ET